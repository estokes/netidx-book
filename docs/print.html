<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Introduction to Netidx</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="overview.html"><strong aria-hidden="true">1.</strong> Overview</a></li><li class="chapter-item expanded "><a href="small_example.html"><strong aria-hidden="true">2.</strong> Small Example</a></li><li class="chapter-item expanded "><a href="complete_system.html"><strong aria-hidden="true">3.</strong> A Complete System</a></li><li class="chapter-item expanded "><a href="administration.html"><strong aria-hidden="true">4.</strong> Administration</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Introduction to Netidx</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#overview-of-netidx" id="overview-of-netidx">Overview of Netidx</a></h1>
<p>Netidx, in a small nutshell, is a library, protocol, and server that
facilitates publishing the value of a variable in one program on one
computer and consuming it in another program on another
computer. There are a lot of details, but making that transaction as
easy as possible while still being secure and performant is the
essential goal.</p>
<h2><a class="header" href="#the-namespace" id="the-namespace">The Namespace</a></h2>
<p>Netidx values are published to a hierarchical tuple space. The
structure of the names look just like a filename, e.g.</p>
<pre><code>/apps/solar/stats/battery_sense_voltage
</code></pre>
<p>Is an example name. Unlike in a file system, in netidx a name may point
to a value, and have children. For example we might have,</p>
<pre><code>/apps/solar/stats/battery_sense_voltage/millivolts
</code></pre>
<p>Where the <code>.../battery_sense_voltage</code> points to the number in volts, and
it's 'millivolts' child gives the same number in millivolts.</p>
<p>Sometimes a name like <code>.../battery_sense_voltage</code> is published deep in
the hierarchy and it's parents are just structure. Unlike the
file system the resolver server will create and delete those structural
containers automatically, there is no need to manually manage them.</p>
<p>The term 'points to' is literal. In netidx the actual data is
completely separate from the names. The names are stored in the
resolver server cluster. Each name points to the ip address and port
of the publisher that actually has the data.</p>
<p>When a client wants to subscribe to the value pointed to by a name, it
queries the resolver server cluster, and is given the addresses of all
the publishers that publish said data point. It then randomly permutes
that list, and tries to subscribe to each address. If one of them
succeeds, then the subscription succeeds, if they all fail then it
doesn't. All the actual data flows from publishers to subscribers
directly without ever going through any kind of centralized
infrastructure.</p>
<h2><a class="header" href="#whats-a-value" id="whats-a-value">What's a Value</a></h2>
<p>So I've said names point to values, but what exactly do I mean by a
'value'.</p>
<ul>
<li>Every non structural name points to a value</li>
<li>Every new subscription immediately delivers it's most recent value</li>
<li>When a value is updated, every subscriber receives the new value</li>
<li>Updates arrive reliably and in the order the publisher made them
(like a TCP stream)</li>
<li>Everything has type 'Value', which is a primitive number, string,
datetime, or byte array</li>
</ul>
<p>Since each value is a primitive, the only structure is, by design, the
hierarchical namespace.</p>
<h2><a class="header" href="#scale" id="scale">Scale</a></h2>
<p>Netidx is meant to be a building block, and as such a lot of thought
has gone into scale. There are multiple different parts of the system
that need to scale. The resolver servers, being the only centralized
piece of infrastructure, are perhaps the most important piece, though
the publisher and subscriber also need to be fast or it won't be worth
using.</p>
<h3><a class="header" href="#resolver-server-scale" id="resolver-server-scale">Resolver Server Scale</a></h3>
<p>The resolver servers implement two strategies to achieve
scale. Replication is the first, one can deploy multiple replicas to
multiple machines in order to protect against a single machine outage,
and also increase throughput. In netidx, the publisher itself is the
primary, and as such it is responsible for replicating the names it
publishes out to all the configured resolver servers. This makes the
system very resilient, as even if the entire resolver server cluster
goes down, the data isn't lost if the publishers are still alive. They
will keep trying to republish their data with linear backoff until
they are killed.</p>
<p>Hierarchy is the second scaling strategy. When a system grows too big
to fit in even a large cluster of servers, then busy parts of the
namespace can be delegated to 'child' server clusters. Readers
familiar with DNS will recognize the basic strategy, though the
details not exactly the same. The administration overhead is similarly
hierarchical, since each cluster config file must only know about it's
immediate superior and immediate children. It's entirely possible for
a large organization to run a central 'root' resolver server cluster
without needing to micro manage the delegation going on in various
organizational units.</p>
<p>I've focused on designing a scaleable architecture, but I should also
mention that the resolver server itself is pretty fast, and uses a
number of strategies to minimize memory use. It's entirely possible to
put 100 million names in a single instance on a single machine with
32 - 64 gig of ram. You get roughly 1 million names per gig of ram,
assuming your paths aren't crazy long. I have not explicitly tested
the resolve throughput, but given that it uses the same infrastructure
as the publisher/subscriber (which I have tested), and what it's
doing, I would not be at all surprised if you could support millions
of resolutions per second per core (yes it will use all your cores).</p>
<h3><a class="header" href="#publishersubscriber-scale" id="publishersubscriber-scale">Publisher/Subscriber Scale</a></h3>
<p>If the theme of taking lots of pages from lots of well established
books and integrating them together has come through by this point
then you've caught on to my design philosophy. In this section we're
going to steal from protbuf, as that is essentially the model, if not
the actual implementation, of the netidx wire protocols.</p>
<p>In protobuf, each record is extensible and rather cleverly
encoded. Each field in the record has a LEB128 Id, followed by a data
value. This allows, for example, an older implementation of a protocol
to talk to a server that has added some new fields without breaking
anything.</p>
<p>Netidx is almost entirely the same on the wire. The subscriber sends
the name it wants to one of the publishers specified by the resolver
server cluster. The publisher looks up that value, and responds with
the id it will use in subsequent messages, along with the current
value. From then on updates to that value transmit only the id, which
is LEB128 encoded, and the updated value. So on the wire, in terms of
overhead, it looks very much like a protobuf record where the fields
are exactly what the subscriber has requested, and nothing more. The
overhead of sending an f64 can be as small as 2 bytes.</p>
<p>Publisher and subscriber performance is fairly good, such that sending
many millions of messages per second is possible. The per message
overhead is on the order of about 70ns of wall clock time per message
with kerberos encryption on (Skylake x86_64 8x5GHz). Obviously that
number depends on the exact hardware you're running on, and it depends
on your workload batching well. A raw TCP socket, coded properly, will
always be faster, the goal is that it won't be faster by enough that
it's worth using.</p>
<p>The subscriber library also implements zero copy decoding for strings
and byte arrays, so it is possible to receive large binary encoded
things quite efficiently.</p>
<h2><a class="header" href="#security" id="security">Security</a></h2>
<p>Ah, the S word. No system remotely like netidx can be taken seriously
without a plausible design for securing data against unauthorized
access, interception, manipulation, etc.</p>
<p>The heart of netidx security is Kerberos v5. There are a lot of
systems I might have used, e.g. openssl + certificates, oauth +
openssl, and I'm sure many others. The reason I chose to use Kerberos
v5 is that most users who want to deploy netidx services already have
Kerberos set up (even if they don't know it) in the form of Microsoft
Active Directory, Samba ADS, Redhat Directory Server, or one of the
many other compatible solutions.</p>
<p>Security is optional. It's possible to deploy a netidx system with no
security at all (and that might even be reasonable), and it's possible
to deploy a system where some publishers require security, and some do
not. If any of the three parties involved in a given transaction
(publisher, resolver, subscriber) request security, then it's
mandatory for all parties of that transaction.</p>
<p>When security is enabled you get the following guarantees,</p>
<ul>
<li>
<p><strong>Mutual Authentication</strong>, the publisher knows the subscriber is who
they claim to be, and the subscriber knows the publisher is who they
claim to be. This applies for the resolver &lt;-&gt; subscriber, and
resolver &lt;-&gt; publisher as well.</p>
</li>
<li>
<p><strong>Confidentiality</strong> and Tamper detection, all messages are encrypted,
and data cannot be altered undetected by a man in the middle.</p>
</li>
<li>
<p><strong>Authorization</strong>, The user subscribing to a given data value is
authorized to do so. The resolver servers maintain a permissions
database specifying who is allowed to do what where in the
tree. Thus the system administrator can centrally control who is
allowed to publish and subscribe where.</p>
</li>
</ul>
<h2><a class="header" href="#subscription-flow" id="subscription-flow">Subscription Flow</a></h2>
<h3><a class="header" href="#components" id="components">Components</a></h3>
<p><img src="subscription-flow-components.png" alt="The Components" /></p>
<p>In the full kerberos enabled version of netidx the following
components are involved.</p>
<ul>
<li>The Kerberos 5 KDC (Key Distribution Center). e.g. The AD Domain Controller.</li>
<li>Resolver Cluster, holds the path of everything published and the
address of the publisher publishing it.</li>
<li>Subscriber</li>
<li>Publisher, holds the actual data, and has previously told the
resolver server about the path of all the data it has.</li>
</ul>
<h3><a class="header" href="#step-1" id="step-1">Step 1</a></h3>
<p><img src="subscription-flow-step1.png" alt="First Step" /></p>
<ol>
<li>The Subscriber asks the KDC for a service ticket to talk to the
Resolver Cluster. Note this only happens once for each user for
some amount of time (usually hours), after which the service ticket
is cached. The subscriber proves it's identity to the KDC using
it's TGT.</li>
<li>The KDC, having checked the validity of the subscriber's identity,
generates a service ticket for the resolver server cluster. NOTE,
Kerberos does not make authorization decisions, it merely allows
entities to prove to each other that they are who they claim to be.</li>
</ol>
<h3><a class="header" href="#step-2" id="step-2">Step 2</a></h3>
<p><img src="subscription-flow-step2.png" alt="Second Step" /></p>
<ol start="3">
<li>The Subscriber uses the service ticket to establish an encrypted
GSSAPI session with the Resolver Cluster. Note this GSSAPI session
will be cached for some time.</li>
<li>Using the session it just established sends a resolve request for
the paths it wants to subscribe to. All traffic is encrypted using
the session.</li>
<li>The Resolver Cluster verifies the presented GSSAPI token and
establishes a secure session, looks up the requested paths, and
returns a number of things to the subscriber for each path.
<ul>
<li>The addresses of all the publishers who are publishing that path</li>
<li>The service principal names of those publishers</li>
<li>The permissions the subscriber has to the path</li>
<li>The authorization token, which is a SHA512 hash of the concatenation of
<ul>
<li>A secret shared by the Resolver Cluster and the Publisher</li>
<li>The path</li>
<li>The permissions</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3><a class="header" href="#step-3" id="step-3">Step 3</a></h3>
<p><img src="subscription-flow-step3.png" alt="Third Step" /></p>
<ol start="6">
<li>The subscriber picks a random publisher from the set of publishers
publishing the path it wants, and requests a service ticket for
that publisher's SPN from the KDC.</li>
<li>The KDC validates the subscriber's TGT and returns a service ticket
for the requested SPN, which will be cached going forward (usually
for several hours).</li>
</ol>
<h3><a class="header" href="#step-4" id="step-4">Step 4</a></h3>
<p><img src="subscription-flow-step4.png" alt="Fourth Step" /></p>
<ol start="8">
<li>
<p>The subscriber uses the service ticket it just obtained to
establish an encrypted GSSAPI session with the publisher, and using
this session it sends a subscribe request, which consists of,</p>
<ul>
<li>The path it wants to subscribe to</li>
<li>The permissions the resolver cluster gave to it</li>
<li>The authorization token</li>
</ul>
</li>
<li>
<p>The publisher validates the subscriber's GSSAPI token and
establishes an encrypted session, and then reads the subscribe
request. It looks up the request path, and assuming it is
publishing that path, it constructs a SHA512 hash value of,</p>
<ul>
<li>The secret it shared with the resolver cluster when it initially
published the path.</li>
<li>The path the subscriber is requesting</li>
<li>The permissions the subscriber claims to have </li>
</ul>
<p>It then checks that it's constructed auth token matches the one the
subscriber presented. Since the subscriber does not know the secret
the publisher shared with the resolver server it is computationally
infeasible for the subscriber to generate a valid hash value for an
arbitrary path or permissions, therefore checking this hash is an
effective proof that the resolver cluster really gave the
subscriber the permissions it is claiming to have.</p>
<p>Assuming all the authentication and authorization checks out, and
the publisher actually publishes the requested value, it sends the
current value back to the publisher along with the ID of the
subscription.</p>
<p>Whenever the value changes the publisher sends the new value along
with the ID of the subscription to the publisher (encrypted using
the GSSAPI session, and over the same TCP session that was
established earlier).</p>
</li>
</ol>
<p>In the case netidx is not configured to use kerberos the KDC is not
involved, and none of the authentication or authorization tokens are
established/sent, it's just a simple matter of look up the address
from the resolver, and then subscribe to the publisher. In that case
all data goes in the clear.</p>
<h2><a class="header" href="#cross-platform" id="cross-platform">Cross Platform</a></h2>
<p>While netidx is primarily developed on PPC64le Linux, it is tested
on aarch64, and x86_64 Linux, Mac OS, and even Windows. It will
probably work on many platforms I haven't tried.</p>
<h1><a class="header" href="#a-small-example" id="a-small-example">A Small Example</a></h1>
<p>Suppose we have a small daemon that we run on many computers on our
network, and it knows many things about them, and does many things. I
won't specify exactly what it does or everything it knows because
that's irrelevant to the example. However suppose one of the things it
knows is the current CPU temperature of the machine it's running on,
and we would like access to that data. We heard about this new netidx
thing, and we'd like to try it out on this small and not very
important case. What code do we need to add to our daemon, and what
options do we have for using the data?</p>
<p>We can modify our Cargo.toml to include netidx, and then add a small
self contained module, publisher.rs</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use anyhow::Result;
use netidx::{
    config::Config,
    path::Path,
    publisher::{Publisher, Val, Value},
    resolver::Auth,
};

#[derive(Clone)]
pub struct HwPub {
    publisher: Publisher,
    cpu_temp: Val,
}

impl HwPub {
    pub async fn new(host: &amp;str, current: f64) -&gt; Result&lt;HwPub&gt; {
        // load the site cluster config from the path in the
        // environment variable NETIDX_CFG, or from
        // dirs::config_dir()/netidx.json if the environment variable
        // isn't specified, or from ~/.netidx.json if the previous
        // file isn't present. Note this uses the cross platform dirs
        // library, so yes, it does something reasonable on windows.
        let cfg = Config::load_default()?;

        // for this small service we don't need authentication
        let auth = Auth::Anonymous;

        // listen on any unique address matching 192.168.0.0/24. If
        // our network was large and complex we might need to make
        // this a passed in configuration option, but lets assume it's
        // simple.
        let publisher = Publisher::new(cfg, auth, &quot;192.168.0.0/24&quot;.parse()?).await?;

        // We're publishing stats about hardware here, so lets put it
        // in /hw/hostname/cpu-temp, that way we keep everything nice
        // and organized.
        let path = Path::from(format!(&quot;/hw/{}/cpu-temp&quot;, host));
        let cpu_temp = publisher.publish(path, Value::F64(current))?;
        Ok(HwPub {
            publisher,
            cpu_temp,
        })
    }

    pub async fn update(&amp;self, current: f64) -&gt; Result&lt;()&gt; {
        // update the current cpu-temp
        self.cpu_temp.update(Value::F64(current));

        // flush the updated values out to subscribers
        self.publisher.flush(None).await
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>Now all we would need to do is create a HwPub on startup, and call
HwPub::update whenever we learn about a new cpu temperature value. Of
course we also need to deploy a resolver server, and distribute a
cluster config to each machine that needs one, that will be covered in
the administration section.</p>
<h2><a class="header" href="#using-the-data-we-just-published" id="using-the-data-we-just-published">Using the Data We Just Published</a></h2>
<p>So now that we have our data in netidx, what are our options for
consuming it? The first option, and often a very good one for a lot of
applications is the shell. The netidx command line tools are designed
to make this interaction easy, here's an example of how we might use
the data.</p>
<pre><code class="language-bash">#! /bin/bash

netidx subscriber $(netidx resolver list /hw | sed -e 's|$|/cpu-temp|') | \
while IFS='|' read path typ temp; do
    IFS='/' read -a pparts &lt;&lt;&lt; &quot;$path&quot;
    if ((temp &gt; 75)); then
        echo &quot;host: ${pparts[2]} cpu tmp is too high: ${temp}&quot;
    fi
done
</code></pre>
<p>Of course we can hook any logic we want into this, the shell is a very
powerful tool after all. For example one thing we might want do is
modify this script slightly, filter the entries with cpu temps that
are too high, and then publish the temperature and the timestamp when
it was observed.</p>
<pre><code class="language-bash">#! /bin/bash

netidx subscriber $(netidx resolver list /hw | sed -e 's|$|/cpu-temp|') | \
while IFS='|' read path typ temp; do
    IFS='/' read -a pparts &lt;&lt;&lt; &quot;$path&quot;
    if ((temp &gt; 75)); then
        echo &quot;/hw/${pparts[2]}/overtemp-ts|string|$(date)&quot;
        echo &quot;/hw/${pparts[2]}/overtemp|f64|$temp&quot;
    fi
done | \
netidx publisher --bind 192.168.0.0/24
</code></pre>
<p>Now we've done something very interesting, we took some data out of
netidx, did a computation on it, and published the result into the
same namespace. We can now subscribe to e.g. /hw/krusty/overtemp-ts
and we will know when that machine last went over temperature. To a
user looking at this namespace in the browser (more on that later)
there is no indication that the over temp data comes from a separate
process, on a separate machine, written by a separate person. It all
just fits together seamlessly as if it was one application.</p>
<p>There is actually a problem here, in that, the above code will not do
quite what you might want it to do. Someone might, for example, want
to write the following additional script.</p>
<pre><code class="language-bash">#! /bin/bash

netidx subscriber $(netidx resolver list /hw | sed -e 's|$|/overtemp-ts|') | \
while IFS='|' read path typ temp; do
    IFS='/' read -a pparts &lt;&lt;&lt; &quot;$path&quot;
    ring-very-loud-alarm ${pparts[2]}
done
</code></pre>
<p>To ring a very loud alarm when an over temp event is detected. This
would in fact work, it just would not be as timely as the author might
expect. The reason is that the subscriber practices linear backoff
when it's instructed to subscribe to a path that doesn't exist. This
is a good practice, in general it reduces the cost of mistakes on the
entire system, but in this case it could result in getting the alarm
minutes, hours, or longer after you should. The good news is there is
a simple solution, we just need to publish all the paths from the
start, but fill them will null until the event actually happens (and
change the above code to ignore the null). That way the subscription
will be successful right away, and the alarm will sound immediately
after the event is detected. So lets change the code ...</p>
<pre><code class="language-bash">#! /bin/bash

cat &lt;(
    netidx resolver list /hw | \
        while IFS='/' read -a pparts
        do
            echo &quot;/hw/${pparts[2]}/overtemp-ts|null&quot;
            echo &quot;/hw/${pparts[2]}/overtemp|null&quot;
        done
) \
&lt;(
   netidx subscriber $(netidx resolver list /hw | sed -e 's|$|/cpu-temp|') | \
       while IFS='|' read path typ temp
       do
            IFS='/' read -a pparts &lt;&lt;&lt; &quot;$path&quot;
            if ((temp &gt; 75)); then
                echo &quot;/hw/${pparts[2]}/overtemp-ts|string|$(date)&quot;
                echo &quot;/hw/${pparts[2]}/overtemp|f64|$temp&quot;
            fi
       done
) | netidx publisher --bind 192.168.0.0/24

</code></pre>
<p>So first we list all the machines in /hw and publish null for
overtemp-ts and overtemp for each one, and then using cat and the
magic of process substitution we append to that the real time list of
actual over temp events.</p>
<h2><a class="header" href="#or-maybe-shell-is-not-your-jam" id="or-maybe-shell-is-not-your-jam">Or Maybe Shell is Not Your Jam</a></h2>
<p>It's entirely possible that thinking about the above solution makes
you shiver and reinforces for you that nothing should ever be written
in shell. In that case it's perfectly possible to do the same thing in
rust.</p>
<pre><pre class="playground"><code class="language-rust">use anyhow::Result;
use futures::{channel::mpsc::channel, prelude::* };
use netidx::{
    config::Config,
    path::Path,
    publisher::{self, Publisher, Value},
    resolver::Auth,
    subscriber::{self, Event, SubId, Subscriber},
};
use chrono::prelude::*;
use std::collections::HashMap;

#[tokio::main]
pub async fn main() -&gt; Result&lt;()&gt; {
    let config = Config::load_default()?;
    let auth = Auth::Anonymous;
    let subscriber = Subscriber::new(config.clone(), auth.clone())?;
    let publisher = Publisher::new(config, auth, &quot;192.168.0.0/24&quot;.parse()?).await?;
    let (tx_current, mut rx_current) = channel(3);
    struct Temp {
        _current: subscriber::Dval, // we need to hang onto this reference
        timestamp: publisher::Val,
        temperature: publisher::Val,
    }
    let temps = subscriber
        .resolver()
        .list(Path::from(&quot;/hw&quot;))
        .await?
        .drain(..)
        .filter_map(|path| path.split('/').nth(2).map(String::from))
        .map(|host| {
            let current = subscriber
                .durable_subscribe(Path::from(format!(&quot;/hw/{}/cpu-temp&quot;, host)));
            current.updates(true, tx_current.clone());
            let timestamp = publisher
                .publish(Path::from(format!(&quot;/hw/{}/overtemp-ts&quot;, host)), Value::Null)?;
            let temperature = publisher
                .publish(Path::from(format!(&quot;/hw/{}/overtemp&quot;, host)), Value::Null)?;
            Ok((current.id(), Temp { _current: current, timestamp, temperature }))
        })
        .collect::&lt;Result&lt;HashMap&lt;SubId, Temp&gt;&gt;&gt;()?;
    publisher.flush(None).await?;
    while let Some(mut batch) = rx_current.next().await {
        for (id, ev) in batch.drain(..) {
            match ev {
                Event::Unsubscribed =&gt; (), // Subscriber will resubscribe automatically
                Event::Update(v) =&gt; {
                    if let Some(temp) = v.cast_f64() {
                        if temp &gt; 75. {
                            let tr = &amp;temps[&amp;id];
                            tr.timestamp.update(Value::DateTime(Utc::now()));
                            tr.temperature.update(Value::F64(temp));
                        }
                    }
                }
            }
        }
        publisher.flush(None).await?
    }
    Ok(())
}
</code></pre></pre>
<p>This does almost exactly the same thing as the shell script, the only
semantic difference being that it sends an actual DateTime value for
the timestamp instead of a string, which would certainly make life
easier for anyone using this data, not to mention it's more
efficient. There is a little more setup and book keeping, but at 62
lines it's hardly a massive program (and it's nearly 20% use
statements).</p>
<h2><a class="header" href="#but-i-just-want-to-look-at-my-data" id="but-i-just-want-to-look-at-my-data">But I Just Want to Look at My Data</a></h2>
<p>Up to now we've covered using the data in various kinds of programs,
but what if you just want to look at it. For that you have two
choices, you can write a custom tool that presents your data exactly
the way you want, or you can use the netidx browser. A custom tool
will always give you more control, but the browser is designed to be
pretty flexible, and it allows you to get to an ok looking solution
really fast. In the case of the data we've been discussing in this
chapter, you get something pretty nice to look at without doing
anything at all.</p>
<p><img src="small-example-table.png" alt="The Browser rendering a table" /></p>
<p>So what's going on here, how did we get a nice looking table out of a
tree? When asked to navigate to a path the browser looks for two kinds
of regular structures, and will draw something appropriate based on
it's findings. One kind is a tree where the 1st level children
themselves have a regular set of children. By regular I mean, with the
same name. In the example we have</p>
<pre><code>/hw/um01-ta07-09/cpu-temp
/hw/um01-ta07-09/overtemp-ts
/hw/um01-ta07-09/overtemp
</code></pre>
<p>But all the 1st level nodes have the same children, so the pattern is,</p>
<pre><code>/hw/${host}/cpu-temp
/hw/${host}/overtemp-ts
/hw/${host}/overtemp
</code></pre>
<p>The browser discovers that regularity, and elects to make a row for
each $host, and a column for each child of $host. In our case, the
data is perfectly regular, and so we end up with a fully populated
table with 3 columns, and a row for each host.</p>
<p>While it's nice to have perfect regularity is not a requirement. By
default in order to be included as a column in the table a 2nd level
child must be shared by at least 50% of the 1st level children (50% of
the rows must have that column). However it is possible to manually
configure which columns the browser should draw, what order they
appear in, and even which (if any) should be the default sort
column. One can do this using the browser's built in view editor (or
by editing some json), and one can publish the result into netidx such
that the browser will automatically use your view definition when the
user navigates to a specific place in the tree. There is more that can
be done with views but that's for another chapter.</p>
<p>In the case where the browser does not find this 2 level regularity,
for example if the current level nodes don't have any children, then
it will draw a table with 1 column (the value) and a row for each
node. This is called vector mode. </p>
<p>If you're worried that this pattern recognition is expensive in cpu,
bandwidth, and round trips, don't be. The resolver server pre computes
tables, so it's just one call for the browser to retrieve that
information for a given location.</p>
<h2><a class="header" href="#wrapping-up" id="wrapping-up">Wrapping Up</a></h2>
<p>In this chapter we saw how we could add a bit of code to an existing
system to expose some of it's data to netidx, and then get quite a bit
of functionality out of that for not much work. I'd like to point out
that all of the components we saw need not have been written by one
person. In fact the people who write them didn't need to talk to each
other in advance (or ever). Having worked in a large organization
where netidx was deployed I found that it's often the case that
someone publishes some interesting data, and then later on other
people see it, do things with it, and publish those things, and after
a while a very compelling application appears almost by magic. Of
course once that happens it's often necessary to get those people
together and talk about how to streamline their design, support the
user base, etc, but that's a really good problem to have because it
means value has been created. Many administrators deploying netidx
might be tempted to lock it completely down so that only &quot;production&quot;
applications are allowed to publish. It's important to think carefully
about how to make sure production applications are always available,
but even still we always included a place in the namespace where
anyone could publish anything, because sometimes magic mushrooms grew
there.</p>
<p>In the next chapter I'll focus on an application written from scratch
to use netidx as it's primary means of communication and control, and
the browser as it's primary user interface.</p>
<h1><a class="header" href="#a-complete-system" id="a-complete-system">A Complete System</a></h1>
<p>In the last chapter we added netidx publishing of one data point to an
existing system, and then explored what we could do with the data. In
this chapter we're going to look at a system designed from scratch to
use netidx as it's primary means of communication and control.</p>
<p>The system we're going to look at is the control program of an off the
grid solar generator. This is a medium sized system, meant to provide
backup power in the event of a long outage, as well as power to any
110vac appliance (up to 20 amps). It consists of a Morningstar
Prostart MPPT charge controller, 4 100 Watt solar panels, 4 lithium
ion batteries arranged in series/parallel to make a 24 volt nominal
200 ah battery pack (about 4.8 Kwh of total storage), and a 3000 Watt
inverter. As the power is quite reliable where I live I often use it
to charge my plug in hybrid car. The Prostar MPPT controller has a
serial port over which it talks modbus, and I've connected a raspberry
pi 3 running bog standard raspbian to that port using a usb to serial
adapter. The pi, called &quot;solar&quot;, is connected to my wifi network and
is joined to my samba ADS domain.</p>
<p>The control program, then, is more or less a simple translation layer
between the modbus interface of the Prostar and netidx. Full source code
<a href="https://github.com/estokes/solar">here</a>.</p>
<p>The main loop takes commands from either the command socket, or the
netidx publisher, and sends them via modbus to the charge controller, e.g.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    loop {
        let msg = select_biased! {
            _ = tick.next() =&gt; ToMainLoop::Tick,
            m = receiver.next() =&gt; match m {
                None =&gt; break,
                Some(m) =&gt; m
            }
        };
        debug!(&quot;run_server: {:?}&quot;, msg);
        match msg {
            ToMainLoop::FromClient(msg, mut reply) =&gt; match msg {
                FromClient::SetCharging(b) =&gt; {
                    send_reply(mb.write_coil(ps::Coil::ChargeDisconnect, !b).await, reply)
                        .await
                }
                FromClient::SetLoad(b) =&gt; {
                    send_reply(mb.write_coil(ps::Coil::LoadDisconnect, !b).await, reply)
                        .await
                }
                FromClient::ResetController =&gt; {
                    send_reply(mb.write_coil(ps::Coil::ResetControl, true).await, reply)
                        .await
                }
                FromClient::LogRotated =&gt; {
                    log = log_fatal!(
                        open_log(&amp;config).await,
                        &quot;failed to open log {}&quot;,
                        break
                    );
                    send_reply(Ok(()), reply).await
                }
                FromClient::TailStats =&gt; tailing.push(reply),
                ...
<span class="boring">}
</span></code></pre></pre>
<p>A message is either a timer Tick, on which we send out (and log)
updated stats, or an actual command, which we handle individually. The
publisher module is fed a new stats record read from modbus on each
timer tick. e.g.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn update(&amp;self, st: &amp;Stats) {
        use chrono::prelude::*;
        self.timestamp
            .update_changed(Value::DateTime(DateTime::&lt;Utc&gt;::from(st.timestamp)));
        self.software_version.update_changed(Value::V32(st.software_version as u32));
        self.battery_voltage_settings_multiplier
            .update(Value::V32(st.battery_voltage_settings_multiplier as u32));
        self.supply_3v3.update_changed(Value::F32(st.supply_3v3.get::&lt;volt&gt;()));
        self.supply_12v.update_changed(Value::F32(st.supply_12v.get::&lt;volt&gt;()));
        self.supply_5v.update_changed(Value::F32(st.supply_5v.get::&lt;volt&gt;()));
        self.gate_drive_voltage
            .update_changed(Value::F32(st.gate_drive_voltage.get::&lt;volt&gt;()));
        self.battery_terminal_voltage
            .update_changed(Value::F32(st.battery_terminal_voltage.get::&lt;volt&gt;()));
    ...
<span class="boring">}
</span></code></pre></pre>
<p>These are all published under <code>/solar/stats</code>, there are a lot of them,
so I won't show them all here, you can read the full source if you're
curious. Essentially it's an infinite loop of read stats from modbus,
log to a file, update netidx, flush netidx, loop.</p>
<h2><a class="header" href="#what-about-control" id="what-about-control">What About Control</a></h2>
<p>The above handles distributing the stats perfectly well, but for
control we need some way to send commands from the subscriber back to
the publisher, and that's where writes come in. If you've read the api
documentation you might have noticed,</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn write(&amp;self, v: Value)
<span class="boring">}
</span></code></pre></pre>
<p>Continuing with the metaphor of exporting variables to a cross machine
global namespace, it fits perfectly well to imagine that we can write
to those variables as well as read from them, publisher willing.</p>
<p>Our program is going to publish three values for control,
<code>/solar/control/charging</code> (to control whether we are charging the
batteries), <code>/solar/control/load</code> (to control whether the inverter is on
or off), and <code>/solar/control/reset</code> (to trigger a controller
reset). These values will all be boolean, and they will be valid for
both read and write. Here is the full code of the control section,</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct PublishedControl {
    charging: Val,
    load: Val,
    reset: Val,
}

impl PublishedControl {
    fn new(publisher: &amp;Publisher, base: &amp;Path) -&gt; Result&lt;Self&gt; {
        Ok(PublishedControl {
            charging: publisher.publish(base.append(&quot;charging&quot;), Value::Null)?,
            load: publisher.publish(base.append(&quot;load&quot;), Value::Null)?,
            reset: publisher.publish(base.append(&quot;reset&quot;), Value::Null)?,
        })
    }

    fn update(&amp;self, st: &amp;Stats) {
        self.charging.update_changed(match st.charge_state {
            ChargeState::Disconnect | ChargeState::Fault =&gt; Value::False,
            ChargeState::UnknownState(_)
            | ChargeState::Absorption
            | ChargeState::BulkMPPT
            | ChargeState::Equalize
            | ChargeState::Fixed
            | ChargeState::Float
            | ChargeState::Night
            | ChargeState::NightCheck
            | ChargeState::Start
            | ChargeState::Slave =&gt; Value::True,
        });
        self.load.update_changed(match st.load_state {
            LoadState::Disconnect | LoadState::Fault | LoadState::LVD =&gt; Value::False,
            LoadState::LVDWarning
            | LoadState::Normal
            | LoadState::NormalOff
            | LoadState::NotUsed
            | LoadState::Override
            | LoadState::Start
            | LoadState::Unknown(_) =&gt; Value::True,
        });
    }

    fn register_writable(&amp;self, channel: fmpsc::Sender&lt;Pooled&lt;Vec&lt;WriteRequest&gt;&gt;&gt;) {
        self.charging.writes(channel.clone());
        self.load.writes(channel.clone());
        self.reset.writes(channel.clone());
    }

    fn process_writes(&amp;self, mut batch: Pooled&lt;Vec&lt;WriteRequest&gt;&gt;) -&gt; Vec&lt;FromClient&gt; {
        batch
            .drain(..)
            .filter_map(|r| {
                if r.id == self.charging.id() {
                    Some(FromClient::SetCharging(bool!(r)))
                } else if r.id == self.load.id() {
                    Some(FromClient::SetLoad(bool!(r)))
                } else if r.id == self.reset.id() {
                    Some(FromClient::ResetController)
                } else {
                    let m = format!(&quot;control id {:?} not recognized&quot;, r.id);
                    warn!(&quot;{}&quot;, &amp;m);
                    if let Some(reply) = r.send_result {
                        reply.send(Value::Error(Chars::from(m)));
                    }
                    None
                }
            })
            .collect()
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>In process_writes we translate each WriteRequest that is targeted at
one of the published controls into a FromClient message that the main
loop will act on. So from the main loop's perspective it doesn't
matter if a command came from netidx, or a command line tool. Note
that it isn't necessary to do any authorization here, the publisher
library has already checked that the resolver server granted the user
making these writes permission to do them.</p>
<p>For the basic day to day use case, that's all we need on the server
side. The entire daemon uses 6.5 MB or ram, and almost no cpu, it
could certainly run on a smaller device, though we depend on tokio,
which means we at least need a real OS under us (for now).</p>
<p>The kerberos configuration for this service is also quite simple,
there is a service principal called svc_solar in samba ADS, and solar
has a keytab installed for it, as well as a cron job that renews it's
TGT every couple of hours. Depending on which OS and KDC you are using
there are different ways you might do this, but that's pretty far out
of our scope.</p>
<h2><a class="header" href="#building-a-custom-gui-with-views" id="building-a-custom-gui-with-views">Building a Custom GUI With Views</a></h2>
<p>What we have is fine as far as it goes, we can view our stats in
vector mode in the browser, and we can write to the controls using the
command line subscriber. For scripting it's great, but when I want to
turn on the inverter on so I can charge the lawn mower, typing
commands at my phone is not ideal, I'd like a gui. This is where
custom browser views come in, here is the finished product,</p>
<p><img src="solar-gui.png" alt="Solar GUI" /></p>
<p>A view definition can be published to the special value .view in a
given directory (e.g. <code>/solar/.view</code>) so it will automatically render
whenever the browser visits that directory, that's what we've done
here. In fact we have our view definition in a file solar.view, and
we're publishing it with the following shell script,</p>
<pre><code class="language-bash">netidx publisher -b 192.168.0.0/24 --spn svc/host@REALM &lt;&lt;EOF
/solar/.view|string|$(cat ~/solar.view)
EOF

</code></pre>
<p>This need not be on the same machine as the control program, as long
as the user running the command has permission to publish under <code>/solar</code>
it will work.</p>
<p>Building the view in the first place can be done using design mode in
the browser, the view can then be saved to a file or written directly
to a netidx path.</p>
<p><img src="browser-design-mode.png" alt="Browser Design Mode" /></p>
<p>Design mode can be activated at any time with the toggle button in the
upper left corner, to the left of save. It splits the window
vertically into two panes, the gui on the right, and the view
definition on the left. The view definition is visualized as a tree of
widgets, with parents higher in the tree containing children, and each
widget having a type. Notice that we've selected a toggle widget in
the tree, and we can see that widget is highlighted blue in the gui,
as we move the selection, the highlight will move, such that we always
know what part of the actual gui we are changing. From a static
picture it's not possible to see this, however the gui is fully
functional in every way while design mode is activated, it isn't some
&quot;special&quot; mode, what you see is exactly what you will get. This
extends to changes, as we make changes the gui will reflect them
immediately, of course if we don't like a change we can simply press
the undo button in the tool bar above the widget tree. </p>
<p>Now lets take a look at the bottom part of the view definition pane,
we see the details of the widget we've selected, the toggle button. We
see there are some layout properties hidden by an expander, every
drawable widget has those, so lets leave them for later. Every widget
that does something in the browser has one or more sources, and one or
more sinks. Sources are where data comes in, and sinks are where data
goes out. Sources are defined in a little domain specific language
called the formula language, which will be specified in detail
later. Sinks use the same syntax but have a different set of
functions.</p>
<p>The semantics of the formula language, and it's syntax, are meant to
be very similar to formulas in a spreadsheet. Where instead of row/col
notation, we use netidx paths to denote refs to other parts of the
sheet. Sources update whenever something they ref updates, and sinks
are updated, and may cause sources to update. And, that's all rather
abstract, lets focus on our example.</p>
<p>Our toggle has two sources, and one sink. The enabled source just
determines if the toggle is interactable, and in our case it's set to
a function <code>constant(bool, true)</code>, which creates a source that always
evaluates to <code>Value::True</code>. The other source, just called source,
determines whether the toggle displays as on or off, and this one is
set to <code>load_path(&quot;/solar/control/charging&quot;)</code>, load_path is a function
that creates a source that subscribes to the netidx path it's given
and updates when the subscription updates. So this straightforwardly
ties the state of the toggle to the value of <code>/solar/control/charging</code>,
when that value changes the toggle state changes. When the user clicks
the toggle, either true or false is written to the sink which is
defined as <code>confirm(store_path(&quot;/solar/control/charging&quot;))</code>. So what
does this do?  Well, store_path pretty obviously creates a sink that
writes whatever value it receives to the specified path, confirm is
more complex. It takes a sink as an argument, and returns a sink that
asks the user to confirm every value it receives. If the user says
yes, then it passes the value on to the passed in sink, in this case
to load_path, otherwise it drops the value.</p>
<p>There are many other useful formulas, and the goal is to make building
simple guis like this dead easy, the majority of the work should be
the layout, and moderately complex guis should be possible. While this
system is already pretty useful it is still under heavy development,
and is by no means finished. Another &quot;limitation&quot; to mention is since
it's built with Gtk+ in Rust it's primarily a desktop application,
though I have tested it on the pinephone under phosh, and even made a
few changes to improve touch support. I will test it on the librem 5
when mine arrives, and it's on my list to build it on windows and
MacOS. Android, and especially iOS versions will not happen, unless
someone else wants to step up.</p>
<h2><a class="header" href="#wrapping-up-1" id="wrapping-up-1">Wrapping Up</a></h2>
<p>In this chapter we saw how an application can be designed more or less
from the start to communicate with the outside world using netidx. We
didn't cover the opportunities for scripting our solar installation
now that we can control it using netidx, but we certainly could do any
of the nice things we did in the last chapter. Instead we saw how we
could build a pretty nice looking and functional gui using browser
custom views, and we got an introduction to the formula language. I
want to point out that with our design having a gui in no way alters
our ability to script and manipulate the system pragmatically.  It's
important to recognize that building a bespoke system with a gui as
complex as the browser view we built AND making it scriptable over the
network in a discoverable, secure, and performant way is not an easy
task, and usually isn't worth doing. However by using netidx we got it
all for free, all we had to do was make our problem fit into netidxs'
data model.</p>
<p>One day I was reflecting on the browser after I had been working on it
for many weeks, and it occurred to me that it is essentially
implementing a distributed version of the model view controller
paradigm. The netidx data model is the model, the view is the widget
tree and the layout properties, and the controller is the formula
language expressions embedded in each widget. However in this version
of MVC we get to reuse the model over the network, and it need not
even run on the same computer, and I think that's pretty cool.</p>
<h1><a class="header" href="#administration" id="administration">Administration</a></h1>
<h2><a class="header" href="#first-things-first" id="first-things-first">First Things First</a></h2>
<p>If you plan to use Kerberos make sure you have it set up properly,
including your KDC, DNS, DHCP, etc. If you need help with kerberos I
suggest <a href="https://www.oreilly.com/library/view/kerberos-the-definitive/0596004036/">the O'rielly book</a>.</p>
<p>Problems with Kerberos/GSSAPI can often be diagnosed by setting
<code>KRB5_TRACE=/dev/stderr</code>, and/or <code>RUST_LOG=debug</code>. GSSAPI errors can
sometimes be less than helpful, but usually the KRB5_TRACE is more
informative.</p>
<h2><a class="header" href="#resources-and-gotchas" id="resources-and-gotchas">Resources and Gotchas</a></h2>
<p>Most installations need not devote massive resources to the resolver
server, however you may want to use at least two instances on
different machines or VMs for redundancy. Here are a few rules of
thumb.</p>
<ul>
<li>Expect to use 1 GB of ram for every 1 million published values</li>
<li>Read operations will use multiple CPU cores (1 core per client)</li>
<li>Write operations use only 1 core and lock out reads (but take on the
order of 100 ns. Work is planned to use all cores and reduce locking.)</li>
<li>Be mindful of the maximum number of available file descriptors when
setting max_connections.</li>
</ul>
<p>If you have, for example, a publisher that wants to publish 20 million
names all at once then you may want to segment that off onto a child
cluster (we'll get to how to do that) to prevent it from locking out
reads for everyone on the main cluster for several minutes (Work is
planned to make this problem better in the resolver server, but it can
never be totally eliminated). A better strategy would be to not write
such a publisher in the first place.</p>
<p>The resolver server drops idle read client connections fairly quickly
(configurable, recommended default 60 seconds), however if you have
many thousands or tens of thousands of read clients that want to do a
lot of reading simultaneously then you may need to raise the maximum
number of file descriptors available, and/or deploy additional
processes to avoid file descriptor exhaustion.</p>
<p>As of this writing the resolver server only runs on Unix, and has only
been extensively tested on Linux. There's no reason it couldn't run on
Windows, it's just a matter of some work around group name resolution
and service integration.</p>
<h2><a class="header" href="#simple-example-configuration" id="simple-example-configuration">Simple Example Configuration</a></h2>
<p>The netidx configuration file is the same for all the different
components of the system, resolver, publisher, and subscriber. By
default it is stored,</p>
<ul>
<li>on Linux: ~/.config/netidx.json</li>
<li>on Windows: ~\AppData\Roaming\netidx.json</li>
<li>on MacOs: ~/Library/Application Support/netidx.json</li>
</ul>
<p>Since the dirs crate is used to discover these paths, they are locally
configurable by OS specific means. </p>
<pre><code class="language-json">{
    &quot;parent&quot;: null,
    &quot;children&quot;: [],
    &quot;pid_file&quot;: &quot;&quot;,
    &quot;addrs&quot;: [&quot;192.168.0.1:4564&quot;],
    &quot;max_connections&quot;: 768,
    &quot;hello_timeout&quot;: 10,
    &quot;reader_ttl&quot;: 60,
    &quot;writer_ttl&quot;: 120,
    &quot;auth&quot;: {
        &quot;Krb5&quot;: {&quot;192.168.0.1:4564&quot;: &quot;netidx/washu-chan.ryu-oh.org@RYU-OH.ORG&quot;}
    }
}
</code></pre>
<p>Here's about the simplest possible Kerberos enabled
configuration. I'll go through each field,</p>
<ul>
<li>parent: null unless this server has a parent, which I'll document later</li>
<li>children: empty unless this server has children, which I'll document later</li>
<li>pid_file: prefix to add to the pid file which will otherwise be
e.g. 0.pid for the first server in the cluster, or 1.pid for the
second, etc.</li>
<li>addrs: The list of all resolver servers in this level of the
cluster, e.g. not children or parents, just this level. When
starting the server you must pass in an index into this array on the
command line as --id to identify which server you want to start.</li>
<li>max_connections: The maximum number of simultaneous connections to
allow (both read and write) before starting to reject new
connections.</li>
<li>hello_timeout: The amount of time to wait for a client to say a
proper hello before dropping the connection.</li>
<li>reader_ttl: The amount of time, in seconds, to keep an idle read
connection open.</li>
<li>writer_ttl: The amount of time, in seconds, to wait for a publisher
to heartbeat before deleting everything it has published. The
publisher will send heartbeats at 1/2 this interval. e.g. 120 means
publishers will heartbeat every minute. Processing a heartbeat does
not take the write lock.</li>
<li>auth: either &quot;Anonymous&quot;, or &quot;Krb5&quot;. If &quot;Krb5&quot;, then a service
principal name should be included for every resolver server in the
cluster. Each resolver server instance must have access to the
corresponding SPN's key via a keytab or other means.</li>
</ul>
<p>When using Kerberos we also need a permissions file in order to run a
resolver server, it's a separate file because it's not meant to be
shared with everyone using the cluster.</p>
<pre><code class="language-json">{
    &quot;/&quot;: {
        &quot;eric@RYU-OH.ORG&quot;: &quot;swlpd&quot;
    },
    &quot;/solar&quot;: {
	    &quot;svc_solar@RYU-OH.ORG&quot;: &quot;pd&quot;
    }
}
</code></pre>
<p>In order to do the corresponding action in netidx a user must have
that permission bit set, no bit, no action.</p>
<p>Permission bits are computed starting from the root proceeding down
the tree to the node being acted on. The bits are accumulated on the
way down, and can also be removed at any point in the tree. Each bit
is represented by a 1 character symbolic tag, e.g.</p>
<ul>
<li>!: Deny, changes the meaning of the following bits to deny the
corresponding permission instead of grant it. Must be the first
character of the permission string.</li>
<li>s: Subscribe</li>
<li>w: Write</li>
<li>l: List</li>
<li>p: Publish</li>
<li>d: Publish default</li>
</ul>
<p>For example if I was subscribing to
<code>/solar/stats/battery_sense_voltage</code> we would walk down the path from
left to right and hit this permission first,</p>
<pre><code class="language-json">&quot;/&quot;: {
    &quot;eric@RYU-OH.ORG&quot;: &quot;swlpd&quot;
},
</code></pre>
<p>This applies to a Kerberos principal &quot;eric@RYU-OH.ORG&quot;, the resolver
server will check the user principal name of the user making the
request, and it will check all the groups that user is a member of,
and if any of those are &quot;eric@RYU-OH.ORG&quot; then it will <code>or</code> the
current permission set with &quot;swlpd&quot;. In this case this gives me
permission to do anything I want in the whole tree (unless it is later
denied). Next we would hit,</p>
<pre><code class="language-json">&quot;/solar&quot;: {
    &quot;svc_solar@RYU-OH.ORG&quot;: &quot;pd&quot;
}
</code></pre>
<p>Which doesn't apply to me, and so would be ignored, and since there
are no more permissions entries my effective permissions at
<code>/solar/stats/battery_sense_voltage</code> are &quot;swlpd&quot;, and so I would be
allowed to subscribe.</p>
<p>Suppose however I changed the above entry,</p>
<pre><code class="language-json">&quot;/solar&quot;: {
    &quot;svc_solar@RYU-OH.ORG&quot;: &quot;pd&quot;,
    &quot;eric@RYU-OH.ORG&quot;: &quot;!swl&quot;,
}
</code></pre>
<p>Now, in our walk, when we arrived at <code>/solar</code>, we would find an entry
that matches me, and we would remove the permission bits s, w, and l,
leaving our effective permissions at
<code>/solar/stats/battery_sense_voltage</code> as &quot;pd&quot;, since that doesn't give
me the right to subscribe my request would be denied. We could, for
example, do this by group instead.</p>
<pre><code class="language-json">&quot;/solar&quot;: {
    &quot;svc_solar@RYU-OH.ORG&quot;: &quot;pd&quot;,
    &quot;RYU-OH\domain admins&quot;: &quot;!swl&quot;,
}
</code></pre>
<p>As you would expect, this deny permission will still apply to me
because I am a member of the domain admins group. A slightly more
subtle point is that permissions are accumulated. For example, if I am
a member of two groups, and both groups have different bits denied,
then all of those bits would be removed. e.g.</p>
<pre><code class="language-json">&quot;/solar&quot;: {
    &quot;svc_solar@RYU-OH.ORG&quot;: &quot;pd&quot;,
    &quot;RYU-OH\domain admins&quot;: &quot;!swl&quot;,
    &quot;RYU-OH\enterprise admins&quot;: &quot;!pd&quot;,
}
</code></pre>
<p>Now my effective permissions under <code>/solar</code> are empty, I can do
nothing. Now, if I am a member of more than one group, and one denies
permissions that the other grants the deny always takes precidence.</p>
<p>Each server cluster is completely independent for permissions. If for
example this cluster had a child cluster, the administrators of that
cluster would be responsible for deciding what permissions file it
should use. It certainly could use the same file, but the point is the
clusters don't talk to each other about permissions (or really
anything else actually).</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
